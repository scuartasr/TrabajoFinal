dim(data[data[,5]==3,])
barplot(as.vector(t(data[,5])), main= "Histograma de comentarios",xlab="Número de comentarios por publicación",ylab="Frecuencia", col="red")
summary(data[,6])
summary(data[,6])
barplot(as.vector(t(data[,5])), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
summary(data[,6])
barplot(as.vector(t(data[,6])), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
hist(as.vector(t(data[,6])), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
?hist
summary(data[,6])
hist(as.vector(t(data[,6])),breaks = c(0,5,10,15,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1052), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
hist(as.vector(t(data[,6])),breaks = c(0,5,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1052), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
summary(data[,6])
hist(as.vector(t(data[,6])),breaks = c(0,5,20,40,60,80,100,300,700,1052), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
summary(data[,6])
barplot(as.vector(t(data[,6])), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
#summary(data[,6])
hist(as.vector(t(data[,6])), main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
#summary(data[,6])
hist(as.vector(t(data[,6])), breaks=c(0,100,300,500,700,800,900,1052),main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
#summary(data[,6])
hist(as.vector(t(data[,6])), breaks=c(1,100,300,500,700,800,900,1052),main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
#summary(data[,6])
hist(as.vector(t(data[,6])), breaks=c(0,100,300,500,700,800,900,1052),main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
#summary(data[,6])
barplot(as.vector(t(data[,6])), breaks=c(0,100,300,500,700,800,900,1052),main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
dim(data[data[,5]==0,])
dim(data[data[,6]==0,])
#summary(data[,6])
barplot(as.vector(t(data[,6])),main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
#summary(data[,6])
hist(as.vector(t(data[,6])),main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="red")
#summary(data[,5])
sd(as.vector(t(data[,5])))
hist(as.vector(t(data[,5])), main= "Histograma de comentarios",xlab="Número de comentarios por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
summary(data[,7])
hist(as.vector(t(data[,7])),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),breaks = c(0,5,10,15,20,25,30),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),breaks = c(0,5,10,15,20,25),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),breaks = c(0,5,10,15,20,25,30,102),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),breaks = c(0,5,10,15,20,25,30,102),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),breaks = c(0,5,20,25,30,102),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),breaks = c(0,15,20,25,30,102),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),breaks = c(0,5,15,20,25,30,102),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
summary(data[,7])
hist(as.vector(t(data[,7])),main= "Histograma de comentarios anononimos",xlab="Número de comentarios anonimos por publicación",ylab="Frecuencia", col="red")
hist(as.vector(t(data[,8]))
hist(as.vector(t(data[,8]))
hist(as.vector(t(data[,8])))
# Precio vs cityMpg según los niveles de bodyStyle
g1 = ggplot(data = data, aes(color = bodyStyle)) +
geom_point(mapping = aes( y = Comentarios
shape = Tema)) +
# Precio vs cityMpg según los niveles de bodyStyle
g1 = ggplot(data = data, aes(color = bodyStyle)) +
geom_point(mapping = aes( y = data$Comentarios
shape = data$Tema)) +
# Precio vs cityMpg según los niveles de bodyStyle
g1 = ggplot(data = data, aes(color = bodyStyle)) +
geom_point(mapping = aes( y = data$Comentarios, shape = data$Tema)) +
labs(color = "Tipo de vehículo") +
labs(title = "Gráfico de dispersión",
subtitle = "de millas recorridas por galón en área urbana contra precio",
caption = "Figura 2.") +
xlab("Millas recorridas por galón en área urbana [mpg]") +
ylab("Precio [$USD]") +
theme_light() +
theme(plot.title = element_text(size = 12, face = "bold"),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(size = 12, color = "gray")) +
scale_color_manual(values = c("#d80000", "#2692ff", "#00d800"))
library(GGally)
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE)
# Precio vs cityMpg según los niveles de bodyStyle
g1 = ggplot(data = data, aes(color = bodyStyle)) +
geom_point(mapping = aes( y = data$Comentarios, shape = data$Tema)) +
labs(color = "Tipo de vehículo") +
labs(title = "Gráfico de dispersión",
subtitle = "de millas recorridas por galón en área urbana contra precio",
caption = "Figura 2.") +
xlab("Millas recorridas por galón en área urbana [mpg]") +
ylab("Precio [$USD]") +
theme_light() +
theme(plot.title = element_text(size = 12, face = "bold"),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(size = 12, color = "gray")) +
scale_color_manual(values = c("#d80000", "#2692ff", "#00d800"))
g1
plot(x=data$Conglomerado, y=data$Peyorativos)
=======
datos = read_xlsx("Resultados.xlsx")
View(datos)
knitr::opts_chunk$set(echo = TRUE)
read.csv("Resultados.csv")
datos = read_xlsx("Resultados.xlsx")
library(readxl)
read.csv("Resultados.csv")
datos = read_xlsx("Resultados.xlsx")
datos_csv = read.csv("Resultados.csv")
datos_xl = read_xlsx("Resultados.xlsx")
library(readxl)
datos_csv = read.csv("Resultados.csv")
datos_xl = read_xlsx("Resultados.xlsx")
View(datos_csv)
datos_csv = read.csv("Resultados.csv",encoding = "UTF-8")
View(datos_csv)
View(datos_xl)
sum(datos_xl$Comentarios)
sum(datos_xl$Conglomerado)
attach(datos_xl)
sum(datos_xl$)
sum(datos_xl$)
table(datos_xl$Conglomerado)
2290/15
class(datos_xl$Comentarios)
class(datos_xl$Peyorativos)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
datos = read_xlsx("Resultados.xlsx")
TotPesosCat = colSums(datos[,4] == "1")
TotPesosCat
TotPesosCat = colSums(datos[,6] == "1")
TotPesosCat
library(dplyr)
datos_1 = datos %>% group_by(Conglomerado) %>% summarise(ti = sum(Peyorativos))
View(datos_1)
View(datos)
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
TotPesosCat2 = colSums(select(datos, contains("Conglomerado")))
TotPesosCat2
TotPesosCat2 = colSums(select(datos, contains("Peyorativo")))
TotPesosCat2
TotPesosCat2 = colSums(select(datos$Conglomerado, contains("Peyorativo")))
media_estimada_peyorativo = sum(datos_1$ti)/89
media_estimada_peyorativo
library(readxl)
library(dplyr)
datos = read_xlsx("Resultados.xlsx")
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
media_estimada_peyorativo = sum(datos_1$ti)/89
media_estimada_peyorativo
media_estimada_peyorativo = sum(datos_1$ti)/89
media_estimada_peyorativo
media_estimada_peyorativo = sum(datos_1$ti)/88
media_estimada_peyorativo
media_estimada_conglomerado_peyorativo = sum(datos_1$ti)/88
media_estimada_conglomerado_peyorativo
media_estimada_peyorativo = media_estimada_conglomerado_peyorativo/15
media_estimada_peyorativo
153*53.89773
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
var_est_tau_c_est
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
var_est_tau_c_est # Varianza estimada
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
# Para mu estimado
M_0 = 2290
var_est_mu_con_est = 1/M_0^2*var_est_tau_c_est
var_est_mu_con_est
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
error_estandar_mu_est = sqrt(var_est_mu_con_est)
error_estandar_mu_est
cuantil_t = qt(0.025,n-1,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
intervalo_tau
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
intervalo_mu
cuantil_t = qt(0.025,n-1,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 95% para tau: ",intervalo_tau)
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
intervalo_mu
cuantil_t = qt(0.025,n-1,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 95% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
intervalo_mu
cuantil_t = qt(0.025,n-1,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 95% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
cat("Intervalo de confianza al 95% para mu: ",intervalo_mu)
knitr::opts_chunk$set(echo = TRUE)
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
datos = read_xlsx("Resultados.xlsx")
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
media_estimada_conglomerado_peyorativo = sum(datos_1$ti)/88
media_estimada_conglomerado_peyorativo
media_estimada_peyorativo = media_estimada_conglomerado_peyorativo/15
media_estimada_peyorativo
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
s_con
s_con
>>>>>>> 5ca1ffe01c2dab5e68a35a74cb78e8d621cc5582
knitr::opts_chunk$set(echo = TRUE)
cuantil_t*error_estandar_tau_c_est # B para total
cuantil_t = qt(0.025,n-1,lower.tail = F)
library(readxl)
library(dplyr)
datos = read_xlsx("Resultados.xlsx")
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
media_estimada_conglomerado_peyorativo = sum(datos_1$ti)/88
media_estimada_conglomerado_peyorativo
media_estimada_peyorativo = media_estimada_conglomerado_peyorativo/15
media_estimada_peyorativo
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
# Para mu estimado
M_0 = 2290
var_est_mu_con_est = 1/M_0^2*var_est_tau_c_est
error_estandar_mu_est = sqrt(var_est_mu_con_est)
error_estandar_mu_est
cuantil_t = qt(0.025,n-1,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 95% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
cat("Intervalo de confianza al 95% para mu: ",intervalo_mu)
cuantil_t*error_estandar_tau_c_est # B para total
cuantil_t*error_estandar_mu_est # B para mu
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
datos = read_xlsx("Resultados.xlsx")
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
media_estimada_conglomerado_peyorativo = sum(datos_1$ti)/88
media_estimada_conglomerado_peyorativo
media_estimada_peyorativo = media_estimada_conglomerado_peyorativo/15
media_estimada_peyorativo
media_estimada_peyorativo = media_estimada_conglomerado_peyorativo/15
media_estimada_peyorativo
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
# Para mu estimado
M_0 = 2290
var_est_mu_con_est = 1/M_0^2*var_est_tau_c_est
error_estandar_mu_est = sqrt(var_est_mu_con_est)
error_estandar_mu_est
#cuantil_t = qt(0.025,n-1,lower.tail = F)
cuantil_t = qnorm(0.025,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 95% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
cat("Intervalo de confianza al 95% para mu: ",intervalo_mu)
#cuantil_t = qt(0.025,n-1,lower.tail = F)
cuantil_t = qnorm(0.05,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 95% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
cat("Intervalo de confianza al 95% para mu: ",intervalo_mu)
#cuantil_t = qt(0.025,n-1,lower.tail = F)
cuantil_t = qnorm(0.05,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 90% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
cat("Intervalo de confianza al 90% para mu: ",intervalo_mu)
cuantil_t = qt(0.05,n-1,lower.tail = F)
#cuantil_t = qnorm(0.05,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 90% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
cat("Intervalo de confianza al 90% para mu: ",intervalo_mu)
#cuantil_t = qt(0.05,n-1,lower.tail = F)
cuantil_t = qnorm(0.05,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_t*error_estandar_tau_c_est, 8246.353 + cuantil_t*error_estandar_tau_c_est)
cat("Intervalo de confianza al 90% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_t*error_estandar_mu_est, media_estimada_peyorativo + cuantil_t*error_estandar_mu_est)
cat("Intervalo de confianza al 90% para mu: ",intervalo_mu)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
datos = read_xlsx("Resultados.xlsx")
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
media_estimada_conglomerado_peyorativo = sum(datos_1$ti)/88
media_estimada_conglomerado_peyorativo
media_estimada_peyorativo = media_estimada_conglomerado_peyorativo/15
media_estimada_peyorativo
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
# Para mu estimado
M_0 = 2290
var_est_mu_con_est = 1/M_0^2*var_est_tau_c_est
error_estandar_mu_est = sqrt(var_est_mu_con_est)
error_estandar_mu_est
cuantil_z = qnorm(0.05,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_z*error_estandar_tau_c_est, 8246.353 + cuantil_z*error_estandar_tau_c_est)
cat("Intervalo de confianza al 90% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_z*error_estandar_mu_est, media_estimada_peyorativo + cuantil_z*error_estandar_mu_est)
cat("Intervalo de confianza al 90% para mu: ",intervalo_mu)
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(gridExtra)
library(knitr)
library(readxl)
library(ggplot2)
library(dplyr)
set.seed(20220126)
# Aleatorización
indices = seq(1, 2295)
aleatorio = sample(indices,
size = 2295,
replace = FALSE)
# Matriz
auxiliar = matrix(aleatorio, ncol = 15, byrow = T)
# Conglomerados
conglomerados = as.data.frame(auxiliar)
save(conglomerados, file = "Conglomerados.RData") # ¿Guardar como .csv?
set.seed(1037670103)
num.congl = seq(1, 153)
muestra = sort(sample(num.congl,
size = 20,
replace = FALSE))
cong.muestreo = conglomerados[which(indices %in% muestra),]
write.csv(cong.muestreo, file = './muestreo.csv')
datos <- read.csv("Datos.csv", encoding = "UTF-8")
datos = na.omit(datos)
datos = datos %>%
mutate(Fecha = as.Date(Fecha, format = "%d/%m/%Y")) %>%
rename(Encuestador = X.U.FEFF.Encuestador)
comen.c = datos %>%
group_by(as.factor(datos$Conglomerado)) %>%
summarise(Comentarios = sum(Comentarios)) %>%
rename(Conglomerado = `as.factor(datos$Conglomerado)`)
anon.c = datos %>%
group_by(as.factor(datos$Conglomerado)) %>%
summarise(Ofensivos = sum(Ofensivos)) %>%
rename(Conglomerado = `as.factor(datos$Conglomerado)`) %>%
rename(Anonimo = Ofensivos)
peyor.c = datos %>%
group_by(as.factor(datos$Conglomerado)) %>%
summarise(Peyorativos = sum(Peyorativos)) %>%
rename(Conglomerado = `as.factor(datos$Conglomerado)`)
resumen = merge(comen.c, peyor.c, by = "Conglomerado")
resumen = merge(resumen, anon.c, by = "Conglomerado")
kable(resumen, caption = "Resultados en los conglomerados del estudio piloto")
suma.pey.c = sum(resumen[, 3])
congs = nrow(resumen)
est.m.c = suma.pey.c / congs
M = 15
est.m = est.m.c/M
options(scipen=999)
N = 153
Mo = M * N
est.t.c = N * est.m.c
# Total
n.ep = 20
totales.cong = as.vector(resumen[, 3])
paso1 = (totales.cong - est.m.c)^2
paso2 = paso1 / (n.ep - 1)
est.var.tc = sum(paso2) * N * (N - n.ep) / n.ep
# Media
est.var.m = est.var.tc / (Mo^2)
alfa = 0.10
z = qnorm((alfa/2), mean  = 0, sd = 1, lower.tail = FALSE)
epsilon = 0.15
Bm = epsilon * est.m
n0.m = ((z^2) * sum(paso2))/((Bm * M))^2
n.m = n0.m / (1 + n0.m/N)
Bt = epsilon * est.t.c
D = (Bt / (z * N))^2
n.t = (N * sum(paso2))/(N*D + sum(paso2))
data<-read_xlsx("Resultados.xlsx")
#summary(data[,5])
hist(as.vector(t(data[,5])), breaks= 25,main= "Histograma de comentarios",xlab="Número de comentarios por publicación",ylab="Frecuencia", col="red",xlim = c(0,1200))
#summary(data[,6])
hist(as.vector(t(data[,6])),breaks=30,main= "Histograma de comentarios peyorativos",xlab="Número de comentarios peyorativos por publicación",ylab="Frecuencia", col="blue",xlim=c(0,400))
#summary(data[,7])
hist(as.vector(t(data[,7])),breaks= 6,main= "Histograma de comentarios anónimos",xlab="Número de comentarios anónimos por publicación",ylab="Frecuencia", col="orange",xlim=c(0,120))
#pol
pol<-data[data[,8]=="Política nacional",]
peyorpol<-sum(pol$Peyorativos)
compol<-sum(pol$Comentarios)
#otro
otro<-data[data[,8]=="Otro",]
peyorotro<-sum(otro$Peyorativos)
comotro<-sum(otro$Comentarios)
#Entrete
ent<-data[data[,8]=="Entretenimiento",]
peyorent<-sum(ent$Peyorativos)
coment<-sum(ent$Comentarios)
#polint
polint<-data[data[,8]=="Política internacional",]
peyorpolint<-sum(polint$Peyorativos)
compolint<-sum(polint$Comentarios)
#Deporte
dep<-data[data[,8]=="Deportes",]
peyordep<-sum(dep$Peyorativos)
comdep<-sum(dep$Comentarios)
#pub
pub<-data[data[,8]=="Publicidad",]
peyorpub<-sum(pub$Peyorativos)
compub<-sum(pub$Comentarios)
Tema_de_las_publicaciones<-c(rep("Política nacional",2),rep("Otro",2),rep("Publicidad",2),rep("Entretenimiento",2),rep("Política internacional",2),rep("Deportes",2))
Tipo_comentario<-rep(c("Comentarios totales","Comentarios Peyorativos"),6)
Número_de_comentarios<-c(compol,peyorpol,comotro,peyorotro,compub,peyorpub,coment,peyorent,compolint,peyorpolint,comdep,peyordep)
dat<-data.frame(Tema_de_las_publicaciones,Tipo_comentario,Número_de_comentarios)
ggplot(dat, aes(fill=Tipo_comentario, y=Número_de_comentarios, x=Tema_de_las_publicaciones)) +
geom_bar(position="dodge", stat="identity")+theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust=0.5))+ggtitle("Gráfico para la Variable Tema")+theme(plot.title = element_text(hjust = 0.5))
datos = read_xlsx("Resultados.xlsx")
datos_1 <- datos %>% group_by(Conglomerado) %>% summarise(n=n(), ti = sum(Peyorativos), mui = sum(Peyorativos)/n())
media_estimada_conglomerado_peyorativo = sum(datos_1$ti)/88
media_estimada_conglomerado_peyorativo
media_estimada_peyorativo = media_estimada_conglomerado_peyorativo/15
media_estimada_peyorativo
# Para tau estimado
N = 153
n = 88
s_con = sum((datos_1$ti - media_estimada_conglomerado_peyorativo)^2)/(n-1)
var_est_tau_c_est = N*(N-n)/n*s_con
error_estandar_tau_c_est = sqrt(var_est_tau_c_est)
error_estandar_tau_c_est # error estándar estimado
# Para mu estimado
M_0 = 2290
var_est_mu_con_est = 1/M_0^2*var_est_tau_c_est
error_estandar_mu_est = sqrt(var_est_mu_con_est)
error_estandar_mu_est
cuantil_z = qnorm(0.05,lower.tail = F)
# Intervalos de confianza para tau
intervalo_tau = c(8246.353 - cuantil_z*error_estandar_tau_c_est, 8246.353 + cuantil_z*error_estandar_tau_c_est)
cat("Intervalo de confianza al 90% para tau: ",intervalo_tau, end="\n")
# Intervalos de confianza para mu
intervalo_mu = c(media_estimada_peyorativo - cuantil_z*error_estandar_mu_est, media_estimada_peyorativo + cuantil_z*error_estandar_mu_est)
cat("Intervalo de confianza al 90% para mu: ",intervalo_mu)
cuantil_z*error_estandar_tau_c_est # B para total
cuantil_z*error_estandar_mu_est # B para mu
